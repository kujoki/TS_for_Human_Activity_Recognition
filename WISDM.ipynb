{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3b501a6-6e40-440a-87f7-5108b78afead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Obtaining dependency information for scikit-learn from https://files.pythonhosted.org/packages/5c/e9/ee572691a3fb05555bcde41826faad29ae4bc1fb07982e7f53d54a176879/scikit_learn-1.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Using cached scikit_learn-1.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy>=1.17.3 in ./venv/lib/python3.10/site-packages (from scikit-learn) (1.25.2)\n",
      "Requirement already satisfied: scipy>=1.5.0 in ./venv/lib/python3.10/site-packages (from scikit-learn) (1.11.2)\n",
      "Collecting joblib>=1.1.1 (from scikit-learn)\n",
      "  Obtaining dependency information for joblib>=1.1.1 from https://files.pythonhosted.org/packages/10/40/d551139c85db202f1f384ba8bcf96aca2f329440a844f924c8a0040b6d02/joblib-1.3.2-py3-none-any.whl.metadata\n",
      "  Using cached joblib-1.3.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn)\n",
      "  Obtaining dependency information for threadpoolctl>=2.0.0 from https://files.pythonhosted.org/packages/81/12/fd4dea011af9d69e1cad05c75f3f7202cdcbeac9b712eea58ca779a72865/threadpoolctl-3.2.0-py3-none-any.whl.metadata\n",
      "  Using cached threadpoolctl-3.2.0-py3-none-any.whl.metadata (10.0 kB)\n",
      "Using cached scikit_learn-1.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.8 MB)\n",
      "Using cached joblib-1.3.2-py3-none-any.whl (302 kB)\n",
      "Using cached threadpoolctl-3.2.0-py3-none-any.whl (15 kB)\n",
      "Installing collected packages: threadpoolctl, joblib, scikit-learn\n",
      "Successfully installed joblib-1.3.2 scikit-learn-1.3.0 threadpoolctl-3.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b094952b-044a-44c9-925d-d1d3a3f3c538",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from sklearn.metrics import (accuracy_score, classification_report,\n",
    "                             confusion_matrix, roc_auc_score)\n",
    "from sklearn.utils import resample\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import logging\n",
    "\n",
    "import torch\n",
    "import torchmetrics\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.utils import resample\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f857232-3c9d-49e9-af22-88cafc8f5f28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18283/379243730.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtred_df[0] = filtred_df[0].apply(lambda x: x.split(','))\n",
      "/tmp/ipykernel_18283/379243730.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtred_df[f'{el}'] = filtred_df[0].apply(lambda x: x[i])\n",
      "/tmp/ipykernel_18283/379243730.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtred_df[f'{el}'] = filtred_df[0].apply(lambda x: x[i])\n",
      "/tmp/ipykernel_18283/379243730.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtred_df[f'{el}'] = filtred_df[0].apply(lambda x: x[i])\n",
      "/tmp/ipykernel_18283/379243730.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtred_df[f'{el}'] = filtred_df[0].apply(lambda x: x[i])\n",
      "/tmp/ipykernel_18283/379243730.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtred_df[f'{el}'] = filtred_df[0].apply(lambda x: x[i])\n",
      "/tmp/ipykernel_18283/379243730.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtred_df[f'{el}'] = filtred_df[0].apply(lambda x: x[i][:-1])\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"WISDM_ar_v1.1_raw.txt\", sep = ' ', header = None)\n",
    "\n",
    "df['lenght'] = df[0].apply(lambda x: x.split(',')).apply(lambda x: len(x))\n",
    "filtred_df = df[~df['lenght'].isin([7, 11])]\n",
    "filtred_df[0] = filtred_df[0].apply(lambda x: x.split(','))\n",
    "\n",
    "columns = ['user','activity','timestamp', 'x-axis', 'y-axis', 'z-axis']\n",
    "for i, el in enumerate(columns):\n",
    "  if i != len(columns)-1:\n",
    "    filtred_df[f'{el}'] = filtred_df[0].apply(lambda x: x[i])\n",
    "  else:\n",
    "    filtred_df[f'{el}'] = filtred_df[0].apply(lambda x: x[i][:-1])\n",
    "\n",
    "filtred_df = filtred_df.drop(columns = [0, 'lenght', 'timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7f64cb3-c364-4b50-a798-3de3283852df",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "filtred_df['activity'] = le.fit_transform(filtred_df['activity'])\n",
    "\n",
    "def transform(x):\n",
    "  try:\n",
    "    x = float(x)\n",
    "  except ValueError:\n",
    "    x = np.nan\n",
    "  return x\n",
    "\n",
    "for el in filtred_df.columns:\n",
    "  filtred_df[el] = filtred_df[el].apply(lambda x: transform(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53873916-ec45-45ad-9afe-854996313c7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7968 7968\n"
     ]
    }
   ],
   "source": [
    "def group_by_user(df, user):\n",
    "  return df[df['user'] == user].reset_index(drop = True)\n",
    "\n",
    "def create_window(df, overlay, window_size, train_x, train_y):\n",
    "  for i in range(0, df.shape[0], overlay):\n",
    "    df_sub = df.iloc[i:i+window_size]\n",
    "\n",
    "    if df_sub.shape[0] == window_size:\n",
    "      train_x.append(df_sub[['x-axis', 'y-axis', 'z-axis']].to_numpy())\n",
    "      train_y.append(df_sub['activity'].mode().iloc[0])\n",
    "\n",
    "  return train_x, train_y\n",
    "\n",
    "\n",
    "train_x = []\n",
    "train_y = []\n",
    "\n",
    "window_size = 100\n",
    "overlay = 50\n",
    "\n",
    "users = filtred_df['user'].unique().tolist()[:12]\n",
    "for user in users:\n",
    "  df_user = group_by_user(filtred_df, user)\n",
    "  create_window(df_user, overlay, window_size, train_x, train_y)\n",
    "\n",
    "print (len(train_x), len(train_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc47e447-6514-4b0d-af74-abceae92451f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtred_df['activity'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1d76e0e-5914-4188-8e8b-9917180f3601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3381 3381\n"
     ]
    }
   ],
   "source": [
    "test_x = []\n",
    "test_y = []\n",
    "\n",
    "users = filtred_df['user'].unique().tolist()[12:18]\n",
    "for user in users:\n",
    "  df_user = group_by_user(filtred_df, user)\n",
    "  create_window(df_user, overlay, window_size, test_x, test_y)\n",
    "\n",
    "print (len(test_x), len(test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1dd88d8c-ab6f-4832-a36b-6c46e9f0296c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8067 8067\n"
     ]
    }
   ],
   "source": [
    "control_x = []\n",
    "control_y = []\n",
    "\n",
    "users = filtred_df['user'].unique().tolist()[18:32]\n",
    "for user in users:\n",
    "  df_user = group_by_user(filtred_df, user)\n",
    "  create_window(df_user, overlay, window_size, control_x, control_y)\n",
    "\n",
    "print (len(control_x), len(control_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f88929b4-92bc-4b00-864e-616602a44370",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(torch.tensor(np.array(train_x).transpose(0, 2, 1), dtype=torch.float32), torch.tensor(np.array(train_y).reshape(-1, 1), dtype=torch.float32))\n",
    "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=False, drop_last = True)\n",
    "\n",
    "test_dataset = TensorDataset(torch.tensor(np.array(test_x).transpose(0, 2, 1), dtype=torch.float32), torch.tensor(np.array(test_y).reshape(-1, 1), dtype=torch.float32))\n",
    "test_loader = DataLoader(test_dataset, batch_size=256, shuffle=False, drop_last = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d7613ead-5cd9-44d5-a0b5-618c51fdb3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "control_dataset = TensorDataset(torch.tensor(np.array(control_x).transpose(0, 2, 1), dtype=torch.float32), torch.tensor(np.array(control_y).reshape(-1, 1), dtype=torch.float32))\n",
    "control_loader = DataLoader(control_dataset, batch_size=256, shuffle=False, drop_last = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "316aa7e0-f33a-42ca-852f-a8b5f79ebe4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 3, 100]) torch.Size([256, 1])\n"
     ]
    }
   ],
   "source": [
    "for inputs, labels in train_loader:\n",
    "  print (inputs.shape, labels.shape)\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36e9d951-40f7-4748-89a6-2f5cffcd2143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 3, 100]) torch.Size([256, 1])\n"
     ]
    }
   ],
   "source": [
    "for inputs, labels in test_loader:\n",
    "  print (inputs.shape, labels.shape)\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "273541d0-c47e-40a7-b1e3-df7cb149dd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvLSTMModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvLSTMModel, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=3, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.batchnorm1 = nn.BatchNorm1d(32)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.conv2 = nn.Conv1d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(64)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool1d(kernel_size=2)\n",
    "        self.lstm = nn.LSTM(input_size=50, hidden_size=64, batch_first=True)\n",
    "        self.dense1 = nn.Linear(64, 128)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.dense2 = nn.Linear(128, 6)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.maxpool(x)\n",
    "        x, _ = self.lstm(x)\n",
    "        x = x[:, -1, :]\n",
    "        x = self.dense1(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.dense2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df62c91f-f717-4f59-b3b3-5e845bb82a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = ConvLSTMModel().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ba02ac4c-1597-4030-b9bc-7712038d68cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(y_true, y_pred):\n",
    "    y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "    accuracy = accuracy_score(y_true, y_pred_labels)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7af9c845-322f-4f7a-bdbf-01f734f23d5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 1/200\n",
      "train_loss 1.781419038772583, train_accuracy 0.30317540322580644\n",
      "validation_loss nan, validation_accuracy 0.41796875\n",
      "epochs 2/200\n",
      "train_loss 1.7767343521118164, train_accuracy 0.34185987903225806\n",
      "validation_loss nan, validation_accuracy 0.44681490384615385\n",
      "epochs 3/200\n",
      "train_loss 1.7719652652740479, train_accuracy 0.3592489919354839\n",
      "validation_loss nan, validation_accuracy 0.4534254807692308\n",
      "epochs 4/200\n",
      "train_loss 1.7670366764068604, train_accuracy 0.3602570564516129\n",
      "validation_loss nan, validation_accuracy 0.4609375\n",
      "epochs 5/200\n",
      "train_loss 1.7618988752365112, train_accuracy 0.3511844758064516\n",
      "validation_loss nan, validation_accuracy 0.4636418269230769\n",
      "epochs 6/200\n",
      "train_loss 1.7564834356307983, train_accuracy 0.3471522177419355\n",
      "validation_loss nan, validation_accuracy 0.4636418269230769\n",
      "epochs 7/200\n",
      "train_loss 1.7507379055023193, train_accuracy 0.3471522177419355\n",
      "validation_loss nan, validation_accuracy 0.4636418269230769\n",
      "epochs 8/200\n",
      "train_loss 1.7446074485778809, train_accuracy 0.3470262096774194\n",
      "validation_loss nan, validation_accuracy 0.4636418269230769\n",
      "epochs 9/200\n",
      "train_loss 1.7380419969558716, train_accuracy 0.3470262096774194\n",
      "validation_loss nan, validation_accuracy 0.4636418269230769\n",
      "epochs 10/200\n",
      "train_loss 1.7309720516204834, train_accuracy 0.34740423387096775\n",
      "validation_loss nan, validation_accuracy 0.46334134615384615\n",
      "epochs 11/200\n",
      "train_loss 1.7233487367630005, train_accuracy 0.34765625\n",
      "validation_loss nan, validation_accuracy 0.46334134615384615\n",
      "epochs 12/200\n",
      "train_loss 1.7151103019714355, train_accuracy 0.3482862903225806\n",
      "validation_loss nan, validation_accuracy 0.46274038461538464\n",
      "epochs 13/200\n",
      "train_loss 1.7061891555786133, train_accuracy 0.3492943548387097\n",
      "validation_loss nan, validation_accuracy 0.4618389423076923\n",
      "epochs 14/200\n",
      "train_loss 1.6965057849884033, train_accuracy 0.3510584677419355\n",
      "validation_loss nan, validation_accuracy 0.45943509615384615\n",
      "epochs 15/200\n",
      "train_loss 1.6859676837921143, train_accuracy 0.35408266129032256\n",
      "validation_loss nan, validation_accuracy 0.4567307692307692\n",
      "epochs 16/200\n",
      "train_loss 1.6745463609695435, train_accuracy 0.359375\n",
      "validation_loss nan, validation_accuracy 0.4489182692307692\n",
      "epochs 17/200\n",
      "train_loss 1.662244439125061, train_accuracy 0.36517137096774194\n",
      "validation_loss nan, validation_accuracy 0.4456129807692308\n",
      "epochs 18/200\n",
      "train_loss 1.649101734161377, train_accuracy 0.38092237903225806\n",
      "validation_loss nan, validation_accuracy 0.4362980769230769\n",
      "epochs 19/200\n",
      "train_loss 1.6351943016052246, train_accuracy 0.3989415322580645\n",
      "validation_loss nan, validation_accuracy 0.43599759615384615\n",
      "epochs 20/200\n",
      "train_loss 1.6206001043319702, train_accuracy 0.42426915322580644\n",
      "validation_loss nan, validation_accuracy 0.4453125\n",
      "epochs 21/200\n",
      "train_loss 1.6053862571716309, train_accuracy 0.4514868951612903\n",
      "validation_loss nan, validation_accuracy 0.46304086538461536\n",
      "epochs 22/200\n",
      "train_loss 1.5896470546722412, train_accuracy 0.48021673387096775\n",
      "validation_loss nan, validation_accuracy 0.48888221153846156\n",
      "epochs 23/200\n",
      "train_loss 1.5735483169555664, train_accuracy 0.5045362903225806\n",
      "validation_loss nan, validation_accuracy 0.5258413461538461\n",
      "epochs 24/200\n",
      "train_loss 1.5573184490203857, train_accuracy 0.5287298387096774\n",
      "validation_loss nan, validation_accuracy 0.54296875\n",
      "epochs 25/200\n",
      "train_loss 1.541198968887329, train_accuracy 0.5404485887096774\n",
      "validation_loss nan, validation_accuracy 0.55859375\n",
      "epochs 26/200\n",
      "train_loss 1.5254266262054443, train_accuracy 0.5550655241935484\n",
      "validation_loss nan, validation_accuracy 0.5561899038461539\n",
      "epochs 27/200\n",
      "train_loss 1.5101770162582397, train_accuracy 0.5555695564516129\n",
      "validation_loss nan, validation_accuracy 0.5543870192307693\n",
      "epochs 28/200\n",
      "train_loss 1.4955817461013794, train_accuracy 0.5526713709677419\n",
      "validation_loss nan, validation_accuracy 0.5450721153846154\n",
      "epochs 29/200\n",
      "train_loss 1.4817320108413696, train_accuracy 0.5446068548387096\n",
      "validation_loss nan, validation_accuracy 0.5324519230769231\n",
      "epochs 30/200\n",
      "train_loss 1.4686928987503052, train_accuracy 0.5328881048387096\n",
      "validation_loss nan, validation_accuracy 0.5210336538461539\n",
      "epochs 31/200\n",
      "train_loss 1.456486463546753, train_accuracy 0.5210433467741935\n",
      "validation_loss nan, validation_accuracy 0.5096153846153846\n",
      "epochs 32/200\n",
      "train_loss 1.445111632347107, train_accuracy 0.5083165322580645\n",
      "validation_loss nan, validation_accuracy 0.5\n",
      "epochs 33/200\n",
      "train_loss 1.4345353841781616, train_accuracy 0.49798387096774194\n",
      "validation_loss nan, validation_accuracy 0.4921875\n",
      "epochs 34/200\n",
      "train_loss 1.424715518951416, train_accuracy 0.4873991935483871\n",
      "validation_loss nan, validation_accuracy 0.48828125\n",
      "epochs 35/200\n",
      "train_loss 1.4155992269515991, train_accuracy 0.47845262096774194\n",
      "validation_loss nan, validation_accuracy 0.4831730769230769\n",
      "epochs 36/200\n",
      "train_loss 1.4071333408355713, train_accuracy 0.47240423387096775\n",
      "validation_loss nan, validation_accuracy 0.48046875\n",
      "epochs 37/200\n",
      "train_loss 1.3992705345153809, train_accuracy 0.46673387096774194\n",
      "validation_loss nan, validation_accuracy 0.47896634615384615\n",
      "epochs 38/200\n",
      "train_loss 1.3919517993927002, train_accuracy 0.4643397177419355\n",
      "validation_loss nan, validation_accuracy 0.47806490384615385\n",
      "epochs 39/200\n",
      "train_loss 1.3851131200790405, train_accuracy 0.4620715725806452\n",
      "validation_loss nan, validation_accuracy 0.4777644230769231\n",
      "epochs 40/200\n",
      "train_loss 1.3786976337432861, train_accuracy 0.4620715725806452\n",
      "validation_loss nan, validation_accuracy 0.4768629807692308\n",
      "epochs 41/200\n",
      "train_loss 1.3726359605789185, train_accuracy 0.4642137096774194\n",
      "validation_loss nan, validation_accuracy 0.47716346153846156\n",
      "epochs 42/200\n",
      "train_loss 1.3668763637542725, train_accuracy 0.4669858870967742\n",
      "validation_loss nan, validation_accuracy 0.4792668269230769\n",
      "epochs 43/200\n",
      "train_loss 1.3613888025283813, train_accuracy 0.4705141129032258\n",
      "validation_loss nan, validation_accuracy 0.48197115384615385\n",
      "epochs 44/200\n",
      "train_loss 1.3561826944351196, train_accuracy 0.47467237903225806\n",
      "validation_loss nan, validation_accuracy 0.48377403846153844\n",
      "epochs 45/200\n",
      "train_loss 1.3512449264526367, train_accuracy 0.4795866935483871\n",
      "validation_loss nan, validation_accuracy 0.4852764423076923\n",
      "epochs 46/200\n",
      "train_loss 1.3465361595153809, train_accuracy 0.48286290322580644\n",
      "validation_loss nan, validation_accuracy 0.4870793269230769\n",
      "epochs 47/200\n",
      "train_loss 1.3420360088348389, train_accuracy 0.4861391129032258\n",
      "validation_loss nan, validation_accuracy 0.4879807692307692\n",
      "epochs 48/200\n",
      "train_loss 1.3377206325531006, train_accuracy 0.4899193548387097\n",
      "validation_loss nan, validation_accuracy 0.48978365384615385\n",
      "epochs 49/200\n",
      "train_loss 1.3335596323013306, train_accuracy 0.4938256048387097\n",
      "validation_loss nan, validation_accuracy 0.49158653846153844\n",
      "epochs 50/200\n",
      "train_loss 1.3295241594314575, train_accuracy 0.4988659274193548\n",
      "validation_loss nan, validation_accuracy 0.4930889423076923\n",
      "epochs 51/200\n",
      "train_loss 1.325588583946228, train_accuracy 0.502898185483871\n",
      "validation_loss nan, validation_accuracy 0.49399038461538464\n",
      "epochs 52/200\n",
      "train_loss 1.3217425346374512, train_accuracy 0.506804435483871\n",
      "validation_loss nan, validation_accuracy 0.4951923076923077\n",
      "epochs 53/200\n",
      "train_loss 1.3179880380630493, train_accuracy 0.5114667338709677\n",
      "validation_loss nan, validation_accuracy 0.49669471153846156\n",
      "epochs 54/200\n",
      "train_loss 1.3143227100372314, train_accuracy 0.5148689516129032\n",
      "validation_loss nan, validation_accuracy 0.4972956730769231\n",
      "epochs 55/200\n",
      "train_loss 1.3107374906539917, train_accuracy 0.5194052419354839\n",
      "validation_loss nan, validation_accuracy 0.4990985576923077\n",
      "epochs 56/200\n",
      "train_loss 1.3072257041931152, train_accuracy 0.5233114919354839\n",
      "validation_loss nan, validation_accuracy 0.5\n",
      "epochs 57/200\n",
      "train_loss 1.3037793636322021, train_accuracy 0.5280997983870968\n",
      "validation_loss nan, validation_accuracy 0.5015024038461539\n",
      "epochs 58/200\n",
      "train_loss 1.3003861904144287, train_accuracy 0.5313760080645161\n",
      "validation_loss nan, validation_accuracy 0.5021033653846154\n",
      "epochs 59/200\n",
      "train_loss 1.2970348596572876, train_accuracy 0.5342741935483871\n",
      "validation_loss nan, validation_accuracy 0.5033052884615384\n",
      "epochs 60/200\n",
      "train_loss 1.2937273979187012, train_accuracy 0.5364163306451613\n",
      "validation_loss nan, validation_accuracy 0.5051081730769231\n",
      "epochs 61/200\n",
      "train_loss 1.2904609441757202, train_accuracy 0.5412046370967742\n",
      "validation_loss nan, validation_accuracy 0.5072115384615384\n",
      "epochs 62/200\n",
      "train_loss 1.2872308492660522, train_accuracy 0.5448588709677419\n",
      "validation_loss nan, validation_accuracy 0.5084134615384616\n",
      "epochs 63/200\n",
      "train_loss 1.2840352058410645, train_accuracy 0.5491431451612904\n",
      "validation_loss nan, validation_accuracy 0.5084134615384616\n",
      "epochs 64/200\n",
      "train_loss 1.2808737754821777, train_accuracy 0.5526713709677419\n",
      "validation_loss nan, validation_accuracy 0.5105168269230769\n",
      "epochs 65/200\n",
      "train_loss 1.2777438163757324, train_accuracy 0.5558215725806451\n",
      "validation_loss nan, validation_accuracy 0.5114182692307693\n",
      "epochs 66/200\n",
      "train_loss 1.2746468782424927, train_accuracy 0.5602318548387096\n",
      "validation_loss nan, validation_accuracy 0.5129206730769231\n",
      "epochs 67/200\n",
      "train_loss 1.2715827226638794, train_accuracy 0.5628780241935484\n",
      "validation_loss nan, validation_accuracy 0.5153245192307693\n",
      "epochs 68/200\n",
      "train_loss 1.2685528993606567, train_accuracy 0.5648941532258065\n",
      "validation_loss nan, validation_accuracy 0.5180288461538461\n",
      "epochs 69/200\n",
      "train_loss 1.2655564546585083, train_accuracy 0.5669102822580645\n",
      "validation_loss nan, validation_accuracy 0.5192307692307693\n",
      "epochs 70/200\n",
      "train_loss 1.2625958919525146, train_accuracy 0.569304435483871\n",
      "validation_loss nan, validation_accuracy 0.5210336538461539\n",
      "epochs 71/200\n",
      "train_loss 1.2596702575683594, train_accuracy 0.5706905241935484\n",
      "validation_loss nan, validation_accuracy 0.5219350961538461\n",
      "epochs 72/200\n",
      "train_loss 1.2567723989486694, train_accuracy 0.5729586693548387\n",
      "validation_loss nan, validation_accuracy 0.5246394230769231\n",
      "epochs 73/200\n",
      "train_loss 1.253901720046997, train_accuracy 0.5758568548387096\n",
      "validation_loss nan, validation_accuracy 0.5282451923076923\n",
      "epochs 74/200\n",
      "train_loss 1.2510586977005005, train_accuracy 0.5787550403225806\n",
      "validation_loss nan, validation_accuracy 0.5303485576923077\n",
      "epochs 75/200\n",
      "train_loss 1.2482396364212036, train_accuracy 0.5808971774193549\n",
      "validation_loss nan, validation_accuracy 0.5327524038461539\n",
      "epochs 76/200\n",
      "train_loss 1.2454426288604736, train_accuracy 0.5829133064516129\n",
      "validation_loss nan, validation_accuracy 0.5336538461538461\n",
      "epochs 77/200\n",
      "train_loss 1.242664098739624, train_accuracy 0.584929435483871\n",
      "validation_loss nan, validation_accuracy 0.5345552884615384\n",
      "epochs 78/200\n",
      "train_loss 1.2399009466171265, train_accuracy 0.5861895161290323\n",
      "validation_loss nan, validation_accuracy 0.5363581730769231\n",
      "epochs 79/200\n",
      "train_loss 1.2371526956558228, train_accuracy 0.5883316532258065\n",
      "validation_loss nan, validation_accuracy 0.5375600961538461\n",
      "epochs 80/200\n",
      "train_loss 1.234419345855713, train_accuracy 0.5894657258064516\n",
      "validation_loss nan, validation_accuracy 0.5393629807692307\n",
      "epochs 81/200\n",
      "train_loss 1.2316975593566895, train_accuracy 0.5902217741935484\n",
      "validation_loss nan, validation_accuracy 0.5420673076923077\n",
      "epochs 82/200\n",
      "train_loss 1.228986144065857, train_accuracy 0.5912298387096774\n",
      "validation_loss nan, validation_accuracy 0.5444711538461539\n",
      "epochs 83/200\n",
      "train_loss 1.2262842655181885, train_accuracy 0.5929939516129032\n",
      "validation_loss nan, validation_accuracy 0.5477764423076923\n",
      "epochs 84/200\n",
      "train_loss 1.2235896587371826, train_accuracy 0.5965221774193549\n",
      "validation_loss nan, validation_accuracy 0.5501802884615384\n",
      "epochs 85/200\n",
      "train_loss 1.220898985862732, train_accuracy 0.5985383064516129\n",
      "validation_loss nan, validation_accuracy 0.5522836538461539\n",
      "epochs 86/200\n",
      "train_loss 1.2182121276855469, train_accuracy 0.6030745967741935\n",
      "validation_loss nan, validation_accuracy 0.5534855769230769\n",
      "epochs 87/200\n",
      "train_loss 1.2155267000198364, train_accuracy 0.6047127016129032\n",
      "validation_loss nan, validation_accuracy 0.5552884615384616\n",
      "epochs 88/200\n",
      "train_loss 1.2128393650054932, train_accuracy 0.6053427419354839\n",
      "validation_loss nan, validation_accuracy 0.5561899038461539\n",
      "epochs 89/200\n",
      "train_loss 1.2101473808288574, train_accuracy 0.6096270161290323\n",
      "validation_loss nan, validation_accuracy 0.5591947115384616\n",
      "epochs 90/200\n",
      "train_loss 1.2074501514434814, train_accuracy 0.6116431451612904\n",
      "validation_loss nan, validation_accuracy 0.5621995192307693\n",
      "epochs 91/200\n",
      "train_loss 1.20474374294281, train_accuracy 0.6131552419354839\n",
      "validation_loss nan, validation_accuracy 0.5643028846153846\n",
      "epochs 92/200\n",
      "train_loss 1.2020313739776611, train_accuracy 0.6147933467741935\n",
      "validation_loss nan, validation_accuracy 0.56640625\n",
      "epochs 93/200\n",
      "train_loss 1.1993173360824585, train_accuracy 0.6159274193548387\n",
      "validation_loss nan, validation_accuracy 0.5697115384615384\n",
      "epochs 94/200\n",
      "train_loss 1.196603536605835, train_accuracy 0.616179435483871\n",
      "validation_loss nan, validation_accuracy 0.5730168269230769\n",
      "epochs 95/200\n",
      "train_loss 1.193888545036316, train_accuracy 0.6168094758064516\n",
      "validation_loss nan, validation_accuracy 0.5736177884615384\n",
      "epochs 96/200\n",
      "train_loss 1.1911718845367432, train_accuracy 0.6173135080645161\n",
      "validation_loss nan, validation_accuracy 0.5766225961538461\n",
      "epochs 97/200\n",
      "train_loss 1.188454270362854, train_accuracy 0.6179435483870968\n",
      "validation_loss nan, validation_accuracy 0.5793269230769231\n",
      "epochs 98/200\n",
      "train_loss 1.1857361793518066, train_accuracy 0.6192036290322581\n",
      "validation_loss nan, validation_accuracy 0.5802283653846154\n",
      "epochs 99/200\n",
      "train_loss 1.18301260471344, train_accuracy 0.620085685483871\n",
      "validation_loss nan, validation_accuracy 0.5823317307692307\n",
      "epochs 100/200\n",
      "train_loss 1.1802793741226196, train_accuracy 0.6205897177419355\n",
      "validation_loss nan, validation_accuracy 0.5835336538461539\n",
      "epochs 101/200\n",
      "train_loss 1.1775376796722412, train_accuracy 0.6215977822580645\n",
      "validation_loss nan, validation_accuracy 0.5853365384615384\n",
      "epochs 102/200\n",
      "train_loss 1.1748062372207642, train_accuracy 0.6224798387096774\n",
      "validation_loss nan, validation_accuracy 0.5877403846153846\n",
      "epochs 103/200\n",
      "train_loss 1.172078013420105, train_accuracy 0.6227318548387096\n",
      "validation_loss nan, validation_accuracy 0.5892427884615384\n",
      "epochs 104/200\n",
      "train_loss 1.1693490743637085, train_accuracy 0.6229838709677419\n",
      "validation_loss nan, validation_accuracy 0.5907451923076923\n",
      "epochs 105/200\n",
      "train_loss 1.1666115522384644, train_accuracy 0.6236139112903226\n",
      "validation_loss nan, validation_accuracy 0.5922475961538461\n",
      "epochs 106/200\n",
      "train_loss 1.1638497114181519, train_accuracy 0.6237399193548387\n",
      "validation_loss nan, validation_accuracy 0.5934495192307693\n",
      "epochs 107/200\n",
      "train_loss 1.161097764968872, train_accuracy 0.6241179435483871\n",
      "validation_loss nan, validation_accuracy 0.5949519230769231\n",
      "epochs 108/200\n",
      "train_loss 1.1583900451660156, train_accuracy 0.6265120967741935\n",
      "validation_loss nan, validation_accuracy 0.5955528846153846\n",
      "epochs 109/200\n",
      "train_loss 1.155684471130371, train_accuracy 0.6294102822580645\n",
      "validation_loss nan, validation_accuracy 0.5964543269230769\n",
      "epochs 110/200\n",
      "train_loss 1.1529756784439087, train_accuracy 0.6314264112903226\n",
      "validation_loss nan, validation_accuracy 0.5970552884615384\n",
      "epochs 111/200\n",
      "train_loss 1.1502615213394165, train_accuracy 0.6336945564516129\n",
      "validation_loss nan, validation_accuracy 0.5979567307692307\n",
      "epochs 112/200\n",
      "train_loss 1.1475350856781006, train_accuracy 0.6360887096774194\n",
      "validation_loss nan, validation_accuracy 0.5985576923076923\n",
      "epochs 113/200\n",
      "train_loss 1.1447970867156982, train_accuracy 0.6369707661290323\n",
      "validation_loss nan, validation_accuracy 0.5994591346153846\n",
      "epochs 114/200\n",
      "train_loss 1.1420446634292603, train_accuracy 0.6382308467741935\n",
      "validation_loss nan, validation_accuracy 0.6000600961538461\n",
      "epochs 115/200\n",
      "train_loss 1.1392827033996582, train_accuracy 0.6386088709677419\n",
      "validation_loss nan, validation_accuracy 0.6009615384615384\n",
      "epochs 116/200\n",
      "train_loss 1.1365182399749756, train_accuracy 0.6398689516129032\n",
      "validation_loss nan, validation_accuracy 0.6030649038461539\n",
      "epochs 117/200\n",
      "train_loss 1.1337555646896362, train_accuracy 0.6412550403225806\n",
      "validation_loss nan, validation_accuracy 0.6048677884615384\n",
      "epochs 118/200\n",
      "train_loss 1.1310007572174072, train_accuracy 0.6415070564516129\n",
      "validation_loss nan, validation_accuracy 0.6075721153846154\n",
      "epochs 119/200\n",
      "train_loss 1.1282503604888916, train_accuracy 0.6420110887096774\n",
      "validation_loss nan, validation_accuracy 0.6075721153846154\n",
      "epochs 120/200\n",
      "train_loss 1.1254948377609253, train_accuracy 0.6430191532258065\n",
      "validation_loss nan, validation_accuracy 0.6099759615384616\n",
      "epochs 121/200\n",
      "train_loss 1.122725248336792, train_accuracy 0.6431451612903226\n",
      "validation_loss nan, validation_accuracy 0.6111778846153846\n",
      "epochs 122/200\n",
      "train_loss 1.1199357509613037, train_accuracy 0.64453125\n",
      "validation_loss nan, validation_accuracy 0.6120793269230769\n",
      "epochs 123/200\n",
      "train_loss 1.1171261072158813, train_accuracy 0.6446572580645161\n",
      "validation_loss nan, validation_accuracy 0.6141826923076923\n",
      "epochs 124/200\n",
      "train_loss 1.1142809391021729, train_accuracy 0.6451612903225806\n",
      "validation_loss nan, validation_accuracy 0.6156850961538461\n",
      "epochs 125/200\n",
      "train_loss 1.1114557981491089, train_accuracy 0.6456653225806451\n",
      "validation_loss nan, validation_accuracy 0.6168870192307693\n",
      "epochs 126/200\n",
      "train_loss 1.108644962310791, train_accuracy 0.6462953629032258\n",
      "validation_loss nan, validation_accuracy 0.6195913461538461\n",
      "epochs 127/200\n",
      "train_loss 1.1058608293533325, train_accuracy 0.6475554435483871\n",
      "validation_loss nan, validation_accuracy 0.6198918269230769\n",
      "epochs 128/200\n",
      "train_loss 1.1031070947647095, train_accuracy 0.6490675403225806\n",
      "validation_loss nan, validation_accuracy 0.6204927884615384\n",
      "epochs 129/200\n",
      "train_loss 1.1003811359405518, train_accuracy 0.6505796370967742\n",
      "validation_loss nan, validation_accuracy 0.6207932692307693\n",
      "epochs 130/200\n",
      "train_loss 1.0976812839508057, train_accuracy 0.6510836693548387\n",
      "validation_loss nan, validation_accuracy 0.6219951923076923\n",
      "epochs 131/200\n",
      "train_loss 1.0949991941452026, train_accuracy 0.6517137096774194\n",
      "validation_loss nan, validation_accuracy 0.6228966346153846\n",
      "epochs 132/200\n",
      "train_loss 1.0923329591751099, train_accuracy 0.6530997983870968\n",
      "validation_loss nan, validation_accuracy 0.6234975961538461\n",
      "epochs 133/200\n",
      "train_loss 1.0896821022033691, train_accuracy 0.6534778225806451\n",
      "validation_loss nan, validation_accuracy 0.6240985576923077\n",
      "epochs 134/200\n",
      "train_loss 1.087046504020691, train_accuracy 0.6542338709677419\n",
      "validation_loss nan, validation_accuracy 0.6246995192307693\n",
      "epochs 135/200\n",
      "train_loss 1.0844274759292603, train_accuracy 0.6546118951612904\n",
      "validation_loss nan, validation_accuracy 0.6259014423076923\n",
      "epochs 136/200\n",
      "train_loss 1.0818217992782593, train_accuracy 0.6553679435483871\n",
      "validation_loss nan, validation_accuracy 0.6259014423076923\n",
      "epochs 137/200\n",
      "train_loss 1.0792242288589478, train_accuracy 0.6559979838709677\n",
      "validation_loss nan, validation_accuracy 0.6268028846153846\n",
      "epochs 138/200\n",
      "train_loss 1.07663893699646, train_accuracy 0.6567540322580645\n",
      "validation_loss nan, validation_accuracy 0.6271033653846154\n",
      "epochs 139/200\n",
      "train_loss 1.0740755796432495, train_accuracy 0.6577620967741935\n",
      "validation_loss nan, validation_accuracy 0.6277043269230769\n",
      "epochs 140/200\n",
      "train_loss 1.0715340375900269, train_accuracy 0.6580141129032258\n",
      "validation_loss nan, validation_accuracy 0.6295072115384616\n",
      "epochs 141/200\n",
      "train_loss 1.0690152645111084, train_accuracy 0.6586441532258065\n",
      "validation_loss nan, validation_accuracy 0.6349158653846154\n",
      "epochs 142/200\n",
      "train_loss 1.0665168762207031, train_accuracy 0.6586441532258065\n",
      "validation_loss nan, validation_accuracy 0.6391225961538461\n",
      "epochs 143/200\n",
      "train_loss 1.0640324354171753, train_accuracy 0.6594002016129032\n",
      "validation_loss nan, validation_accuracy 0.6415264423076923\n",
      "epochs 144/200\n",
      "train_loss 1.0615599155426025, train_accuracy 0.6596522177419355\n",
      "validation_loss nan, validation_accuracy 0.6424278846153846\n",
      "epochs 145/200\n",
      "train_loss 1.0590945482254028, train_accuracy 0.6597782258064516\n",
      "validation_loss nan, validation_accuracy 0.6430288461538461\n",
      "epochs 146/200\n",
      "train_loss 1.0566294193267822, train_accuracy 0.6599042338709677\n",
      "validation_loss nan, validation_accuracy 0.6433293269230769\n",
      "epochs 147/200\n",
      "train_loss 1.0541692972183228, train_accuracy 0.6602822580645161\n",
      "validation_loss nan, validation_accuracy 0.6436298076923077\n",
      "epochs 148/200\n",
      "train_loss 1.051727056503296, train_accuracy 0.6610383064516129\n",
      "validation_loss nan, validation_accuracy 0.6448317307692307\n",
      "epochs 149/200\n",
      "train_loss 1.0492991209030151, train_accuracy 0.6617943548387096\n",
      "validation_loss nan, validation_accuracy 0.6454326923076923\n",
      "epochs 150/200\n",
      "train_loss 1.0468833446502686, train_accuracy 0.6619203629032258\n",
      "validation_loss nan, validation_accuracy 0.6463341346153846\n",
      "epochs 151/200\n",
      "train_loss 1.044481635093689, train_accuracy 0.6622983870967742\n",
      "validation_loss nan, validation_accuracy 0.6472355769230769\n",
      "epochs 152/200\n",
      "train_loss 1.042094111442566, train_accuracy 0.663054435483871\n",
      "validation_loss nan, validation_accuracy 0.6466346153846154\n",
      "epochs 153/200\n",
      "train_loss 1.0397218465805054, train_accuracy 0.663054435483871\n",
      "validation_loss nan, validation_accuracy 0.6466346153846154\n",
      "epochs 154/200\n",
      "train_loss 1.0373637676239014, train_accuracy 0.6640625\n",
      "validation_loss nan, validation_accuracy 0.6472355769230769\n",
      "epochs 155/200\n",
      "train_loss 1.0350183248519897, train_accuracy 0.6643145161290323\n",
      "validation_loss nan, validation_accuracy 0.6484375\n",
      "epochs 156/200\n",
      "train_loss 1.032684564590454, train_accuracy 0.6645665322580645\n",
      "validation_loss nan, validation_accuracy 0.6484375\n",
      "epochs 157/200\n",
      "train_loss 1.030356764793396, train_accuracy 0.665070564516129\n",
      "validation_loss nan, validation_accuracy 0.6490384615384616\n",
      "epochs 158/200\n",
      "train_loss 1.0280263423919678, train_accuracy 0.6651965725806451\n",
      "validation_loss nan, validation_accuracy 0.6550480769230769\n",
      "epochs 159/200\n",
      "train_loss 1.0257219076156616, train_accuracy 0.6651965725806451\n",
      "validation_loss nan, validation_accuracy 0.6655649038461539\n",
      "epochs 160/200\n",
      "train_loss 1.0234313011169434, train_accuracy 0.6649445564516129\n",
      "validation_loss nan, validation_accuracy 0.66796875\n",
      "epochs 161/200\n",
      "train_loss 1.0211519002914429, train_accuracy 0.6651965725806451\n",
      "validation_loss nan, validation_accuracy 0.6691706730769231\n",
      "epochs 162/200\n",
      "train_loss 1.0188802480697632, train_accuracy 0.6654485887096774\n",
      "validation_loss nan, validation_accuracy 0.6700721153846154\n",
      "epochs 163/200\n",
      "train_loss 1.0166159868240356, train_accuracy 0.6659526209677419\n",
      "validation_loss nan, validation_accuracy 0.6703725961538461\n",
      "epochs 164/200\n",
      "train_loss 1.0143572092056274, train_accuracy 0.6662046370967742\n",
      "validation_loss nan, validation_accuracy 0.6703725961538461\n",
      "epochs 165/200\n",
      "train_loss 1.0121067762374878, train_accuracy 0.666960685483871\n",
      "validation_loss nan, validation_accuracy 0.6703725961538461\n",
      "epochs 166/200\n",
      "train_loss 1.009861707687378, train_accuracy 0.6673387096774194\n",
      "validation_loss nan, validation_accuracy 0.6709735576923077\n",
      "epochs 167/200\n",
      "train_loss 1.0076217651367188, train_accuracy 0.6682207661290323\n",
      "validation_loss nan, validation_accuracy 0.6709735576923077\n",
      "epochs 168/200\n",
      "train_loss 1.0053825378417969, train_accuracy 0.6692288306451613\n",
      "validation_loss nan, validation_accuracy 0.6712740384615384\n",
      "epochs 169/200\n",
      "train_loss 1.0031403303146362, train_accuracy 0.6697328629032258\n",
      "validation_loss nan, validation_accuracy 0.6721754807692307\n",
      "epochs 170/200\n",
      "train_loss 1.0008951425552368, train_accuracy 0.6706149193548387\n",
      "validation_loss nan, validation_accuracy 0.6724759615384616\n",
      "epochs 171/200\n",
      "train_loss 0.9986448884010315, train_accuracy 0.6716229838709677\n",
      "validation_loss nan, validation_accuracy 0.6724759615384616\n",
      "epochs 172/200\n",
      "train_loss 0.9964011311531067, train_accuracy 0.6720010080645161\n",
      "validation_loss nan, validation_accuracy 0.6724759615384616\n",
      "epochs 173/200\n",
      "train_loss 0.9941958785057068, train_accuracy 0.6727570564516129\n",
      "validation_loss nan, validation_accuracy 0.6739783653846154\n",
      "epochs 174/200\n",
      "train_loss 0.9920055866241455, train_accuracy 0.6731350806451613\n",
      "validation_loss nan, validation_accuracy 0.6736778846153846\n",
      "epochs 175/200\n",
      "train_loss 0.9898268580436707, train_accuracy 0.6731350806451613\n",
      "validation_loss nan, validation_accuracy 0.6739783653846154\n",
      "epochs 176/200\n",
      "train_loss 0.9876588582992554, train_accuracy 0.6735131048387096\n",
      "validation_loss nan, validation_accuracy 0.6742788461538461\n",
      "epochs 177/200\n",
      "train_loss 0.9855009317398071, train_accuracy 0.6737651209677419\n",
      "validation_loss nan, validation_accuracy 0.6742788461538461\n",
      "epochs 178/200\n",
      "train_loss 0.983349084854126, train_accuracy 0.6741431451612904\n",
      "validation_loss nan, validation_accuracy 0.6736778846153846\n",
      "epochs 179/200\n",
      "train_loss 0.981205403804779, train_accuracy 0.674773185483871\n",
      "validation_loss nan, validation_accuracy 0.6742788461538461\n",
      "epochs 180/200\n",
      "train_loss 0.9790670275688171, train_accuracy 0.6754032258064516\n",
      "validation_loss nan, validation_accuracy 0.6739783653846154\n",
      "epochs 181/200\n",
      "train_loss 0.9769349694252014, train_accuracy 0.6759072580645161\n",
      "validation_loss nan, validation_accuracy 0.6742788461538461\n",
      "epochs 182/200\n",
      "train_loss 0.9748050570487976, train_accuracy 0.6765372983870968\n",
      "validation_loss nan, validation_accuracy 0.6754807692307693\n",
      "epochs 183/200\n",
      "train_loss 0.9726759791374207, train_accuracy 0.676789314516129\n",
      "validation_loss nan, validation_accuracy 0.6760817307692307\n",
      "epochs 184/200\n",
      "train_loss 0.9705474376678467, train_accuracy 0.6775453629032258\n",
      "validation_loss nan, validation_accuracy 0.6763822115384616\n",
      "epochs 185/200\n",
      "train_loss 0.9684192538261414, train_accuracy 0.6775453629032258\n",
      "validation_loss nan, validation_accuracy 0.6766826923076923\n",
      "epochs 186/200\n",
      "train_loss 0.9662957191467285, train_accuracy 0.6774193548387096\n",
      "validation_loss nan, validation_accuracy 0.6766826923076923\n",
      "epochs 187/200\n",
      "train_loss 0.9641754627227783, train_accuracy 0.6776713709677419\n",
      "validation_loss nan, validation_accuracy 0.6772836538461539\n",
      "epochs 188/200\n",
      "train_loss 0.9620553255081177, train_accuracy 0.6776713709677419\n",
      "validation_loss nan, validation_accuracy 0.6778846153846154\n",
      "epochs 189/200\n",
      "train_loss 0.959934413433075, train_accuracy 0.6777973790322581\n",
      "validation_loss nan, validation_accuracy 0.6790865384615384\n",
      "epochs 190/200\n",
      "train_loss 0.9578128457069397, train_accuracy 0.6784274193548387\n",
      "validation_loss nan, validation_accuracy 0.6799879807692307\n",
      "epochs 191/200\n",
      "train_loss 0.9556881785392761, train_accuracy 0.6791834677419355\n",
      "validation_loss nan, validation_accuracy 0.6799879807692307\n",
      "epochs 192/200\n",
      "train_loss 0.9535594582557678, train_accuracy 0.6794354838709677\n",
      "validation_loss nan, validation_accuracy 0.6808894230769231\n",
      "epochs 193/200\n",
      "train_loss 0.9514310956001282, train_accuracy 0.6799395161290323\n",
      "validation_loss nan, validation_accuracy 0.6805889423076923\n",
      "epochs 194/200\n",
      "train_loss 0.9493028521537781, train_accuracy 0.6803175403225806\n",
      "validation_loss nan, validation_accuracy 0.6805889423076923\n",
      "epochs 195/200\n",
      "train_loss 0.9471759796142578, train_accuracy 0.6809475806451613\n",
      "validation_loss nan, validation_accuracy 0.6805889423076923\n",
      "epochs 196/200\n",
      "train_loss 0.9450507760047913, train_accuracy 0.6813256048387096\n",
      "validation_loss nan, validation_accuracy 0.6802884615384616\n",
      "epochs 197/200\n",
      "train_loss 0.9429275989532471, train_accuracy 0.6814516129032258\n",
      "validation_loss nan, validation_accuracy 0.6799879807692307\n",
      "epochs 198/200\n",
      "train_loss 0.9408037066459656, train_accuracy 0.6817036290322581\n",
      "validation_loss nan, validation_accuracy 0.6796875\n",
      "epochs 199/200\n",
      "train_loss 0.9386784434318542, train_accuracy 0.6819556451612904\n",
      "validation_loss nan, validation_accuracy 0.6796875\n",
      "epochs 200/200\n",
      "train_loss 0.9365494251251221, train_accuracy 0.6827116935483871\n",
      "validation_loss nan, validation_accuracy 0.6790865384615384\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "def Train():\n",
    "\n",
    "    running_loss = .0\n",
    "    y_true = []\n",
    "    y_pred_probs = []\n",
    "    model.train()\n",
    "\n",
    "    for idx, (inputs,labels) in enumerate(train_loader):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(inputs.float())\n",
    "        loss = criterion(preds, labels.squeeze().long())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss\n",
    "\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "        y_pred_probs.extend(preds.detach().cpu().numpy())\n",
    "\n",
    "    train_loss = running_loss/len(train_loader)\n",
    "    train_losses.append(train_loss.detach().numpy())\n",
    "\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred_probs = np.array(y_pred_probs)\n",
    "    accuracy = calculate_accuracy(y_true, y_pred_probs)\n",
    "\n",
    "    print(f'train_loss {train_loss}, train_accuracy {accuracy}')\n",
    "\n",
    "def Valid():\n",
    "    running_loss = .0\n",
    "    y_true = []\n",
    "    y_pred_probs = []\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, (inputs, labels) in enumerate(test_loader):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            preds = model(inputs.float())\n",
    "            loss = criterion(preds, labels.squeeze().long())\n",
    "            running_loss += loss\n",
    "\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            y_pred_probs.extend(preds.detach().cpu().numpy())\n",
    "\n",
    "        valid_loss = running_loss/len(test_loader)\n",
    "        valid_losses.append(valid_loss.detach().numpy())\n",
    "\n",
    "        y_true = np.array(y_true)\n",
    "        y_pred_probs = np.array(y_pred_probs)\n",
    "        accuracy = calculate_accuracy(y_true, y_pred_probs)\n",
    "\n",
    "        print(f'validation_loss {valid_loss}, validation_accuracy {accuracy}')\n",
    "    return valid_losses, accuracy\n",
    "\n",
    "epochs = 200\n",
    "for epoch in range(epochs):\n",
    "    print('epochs {}/{}'.format(epoch+1,epochs))\n",
    "    Train()\n",
    "    Valid()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "07252e08-4236-4f35-9333-43cbc0cad208",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7ff3175c24d0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_losses,label='train_loss')\n",
    "plt.plot(valid_losses,label='valid_loss')\n",
    "plt.title('MSE Loss')\n",
    "plt.ylim(0, 4)\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8de6c0b8-9a04-4446-acf7-0aad80f0058a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation_accuracy 0.6202116935483871\n"
     ]
    }
   ],
   "source": [
    "y_true = []\n",
    "y_pred_probs = []\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for idx, (inputs, labels) in enumerate(control_loader):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(inputs.float())\n",
    "        loss = criterion(preds, labels.squeeze().long())\n",
    "\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "        y_pred_probs.extend(preds.detach().cpu().numpy())\n",
    "\n",
    "\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred_probs = np.array(y_pred_probs)\n",
    "    accuracy = calculate_accuracy(y_true, y_pred_probs)\n",
    "\n",
    "    print(f'validation_accuracy {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1328342-9da1-4011-a08f-ae934e86767d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
